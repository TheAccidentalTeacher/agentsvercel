# AI Context Loader - MASTER INDEX

## Purpose
This document serves as the **definitive master index** for loading complete project context into AI conversations. Reference this at the start of important conversations to maintain continuity and ensure access to the full vision, current state, and future plans.

**Last Updated**: December 16, 2025 (Evening Session)  
**Status**: Phase 6 Day 3 (Multi-Agent Analysis) - COMPLETE & FULLY FUNCTIONAL

---

## üìö Core Context Files

### 1. Biography & Mission (WHO WE ARE)
- **[01-BIOGRAPHY-STORY.md](../../01-BIOGRAPHY-STORY.md)** - Scott's personal story and journey
- **[MISSION-STATEMENT.md](../../MISSION-STATEMENT.md)** - Core mission and values
- **[FELLOWSHIP_GUIDE.md](../../FELLOWSHIP_GUIDE.md)** - Team collaboration principles

### 2. Strategic Planning (WHAT WE'RE BUILDING)
- **[03-STRATEGIC-PLAN.md](../../03-STRATEGIC-PLAN.md)** - Overall strategic direction
- **[MASTER-PLAN.md](../../MASTER-PLAN.md)** - Original homeschool platform vision
- **[PROJECT_STATUS.md](../../PROJECT_STATUS.md)** - Current project status (updated weekly)
- **[COGNITIVE_AMPLIFICATION_VISION.md](../COGNITIVE_AMPLIFICATION_VISION.md)** - Ultimate vision for UCAS

### 3. Technical Implementation (HOW IT WORKS)
- **[IMPLEMENTATION_PLAN_FINAL.md](../../IMPLEMENTATION_PLAN_FINAL.md)** - Original game editor implementation
- **[CURRENT_STATUS.md](../../CURRENT_STATUS.md)** - Live development status (updated daily)
- **[MASTER_ROADMAP.md](../MASTER_ROADMAP.md)** - Historical game editor roadmap
- **[TECHNICAL_ARCHITECTURE.md](../TECHNICAL_ARCHITECTURE.md)** - System architecture and design

### 4. Multi-Agent System (THE AI CONSORTIUM)
- **[AGENT_COUNCIL_GUIDE.md](../../AGENT_COUNCIL_GUIDE.md)** - Multi-agent architecture
- **[LANGGRAPH_MULTIAGENT_PLAN.md](../../LANGGRAPH_MULTIAGENT_PLAN.md)** - LangGraph implementation
- **[personas/README.md](../../personas/README.md)** - 12-persona system overview

### 5. Phase Documentation (COMPLETED WORK)
- **Phase 0**: Initial Setup (‚úÖ COMPLETE - Nov 2025)
- **Phase 1**: AI Framework & 12 Personas (‚úÖ COMPLETE - Dec 1-5)
- **Phase 1.5**: Polish & Branding (‚úÖ COMPLETE - Dec 5-6)
- **Phase 2**: Multi-Agent Orchestration (‚úÖ COMPLETE - Dec 6-10)
  - Sprint 1: LangGraph Foundation
  - Sprint 2: Orchestration Agents
  - Sprint 3: Backend API
  - Sprint 4: UI Integration
- **Phase 3**: Memory System (‚úÖ COMPLETE - Dec 10-11)
- **Phase 4**: Conversation Mode (‚úÖ COMPLETE - Dec 11-12)
- **Phase 5**: Polish & Documentation (‚úÖ COMPLETE - Dec 13-14)

### 6. Current Phase Documentation (IN PROGRESS)
**Phase 6: Deep Research Engine** (Dec 14-16, 2025)
- **[PHASE_6_IMPLEMENTATION_PLAN.md](../../PHASE_6_IMPLEMENTATION_PLAN.md)** - Complete day-by-day plan
- **[PHASE_6_SETUP.md](../../PHASE_6_SETUP.md)** - API configuration guide
- **[PHASE_6_DAY_1_COMPLETE.md](../../PHASE_6_DAY_1_COMPLETE.md)** - Search foundation complete
- **Phase 6 Day 2**: Content extraction ‚úÖ COMPLETE (Dec 14)
- **Phase 6 Day 3**: Multi-agent analysis ‚úÖ COMPLETE (Dec 16)
  * ResearchAnalyzer with 12-persona orchestration
  * Intelligent chunk sampling (fixes token overflow)
  * Scrollable output UI (no more hidden content!)
  * Executive synthesis + individual perspectives
  * Beautiful collapsible UI with markdown rendering

### 7. Future Capabilities Roadmap (THE BIG PICTURE)
- **[FUTURE_CAPABILITIES_ROADMAP.md](../FUTURE_CAPABILITIES_ROADMAP.md)** - **READ THIS FOR ALL FUTURE PLANS**

---

## üéØ Complete Project Phases Overview

### ‚úÖ COMPLETED (Phases 0-5)
The multi-agent consortium is fully functional with 12 specialized personas, 4 orchestration modes (Panel, Consensus, Debate, Conversation), memory system, and comprehensive documentation.

### üîÑ IN PROGRESS (Phase 6)
**Deep Research Engine** - Perplexity-like research with multi-agent analysis - ‚úÖ WEEK 1-6 COMPLETE!
- **Week 1-2**: Search Foundation ‚úÖ (Tavily, Brave, Serper APIs integrated)
- **Week 3-4**: Content Processing ‚úÖ (Mozilla Readability, semantic chunking)
- **Week 5-6**: Multi-Agent Analysis ‚úÖ (12-persona research analysis - WORKING!)
  * Token limit fix: Intelligent sampling prevents overflow
  * UI fix: Scrollable output shows all content
  * Executive synthesis + 12 perspective analyses
  * Expandable/collapsible UI with markdown rendering
- **Week 7-8**: Memory & Export ‚è≥ (NEXT UP - starting soon!)

### üìã FUTURE PHASES (Complete Roadmap)

#### Phase 7: YouTube & Video Intelligence
**Goal**: Process video content like Brisk Education
- Video summarization with timestamps
- Transcript analysis and searchable content
- Multi-video synthesis and comparison
- Graphic organizer generation from videos
- Educational assessment creation

#### Phase 8: Creative Content Generation
**Goal**: Full multimedia creation capabilities
- **Month 4**: Image generation (DALL-E, Midjourney, Stable Diffusion)
  * Smart prompting with multi-agent optimization
  * Educational diagrams and infographics
  * Batch generation and variation
- **Month 5**: Video & audio creation
  * Text-to-video with RunwayML, Synthesia
  * Voice generation with ElevenLabs
  * Podcast and music creation

#### Phase 9: Development Environment
**Goal**: Replace VS Code with AI-native coding tool
- **Month 6**: Code intelligence
  * Monaco editor integration
  * Multi-agent code review (Architect + Debugger + Strategist)
  * Context-aware completion
  * Refactoring assistant
- **Month 7**: Project management
  * Project scaffolding with agent discussion
  * Build automation and deployment
  * Test generation and coverage

#### Phase 10: Integration Ecosystem
**Goal**: Seamless productivity tool integration
- **Month 8**: Google & Microsoft
  * Google Workspace (Docs, Sheets, Slides, Gmail)
  * Microsoft Office (Word, Excel, PowerPoint)
- **Month 9**: Browser & productivity
  * Browser extension for universal access
  * Notion, Trello, Asana integration
  * Slack/Teams bot integration

#### Phase 11: Advanced Intelligence & Autonomy
**Goal**: Persistent memory and autonomous agents
- **Month 10**: Memory & learning
  * Long-term memory system
  * Personal knowledge base
  * Preference learning
  * Visual knowledge graph
- **Month 11**: Autonomous agents
  * Background processing
  * Scheduled tasks (overnight research)
  * Proactive assistance
  * Multi-step workflows: Research ‚Üí Analyze ‚Üí Create ‚Üí Deploy
- **Month 12**: Collaboration
  * Shared workspaces
  * Team features
  * Role-based access
  * Collective intelligence

#### Phase 12: Scale & Ecosystem (Year 2)
- **Q1**: Public API & plugin system
- **Q2**: Mobile & cross-platform apps
- **Q3**: Advanced AI (fine-tuning, multi-modal)
- **Q4**: Enterprise features & white-labeling

---

## üë§ Quick Identity Summary

### Who You Are (Scott Somers)
- **Reformed Baptist Christian** homeschool educator and father
- **Theological Foundation**: Spurgeon, MacArthur, Piper, Sproul (Reformed theology)
- **Background**: 
  * Undergrad: Theology
  * Grad: Elementary Education (in progress)
  * Experience: Homeschool dad + public school teacher (rural Alaska, Title 1)
  * Deacon with deep theological knowledge
- **Philosophy**: "My life is better because you're in it" - meeting kids where they are
- **Vision**: Building tools that reflect YOUR worldview and values (Reformed, classical education)

### What We're Building
**Universal Cognitive Amplification System (UCAS)**
- **Primary**: Multi-Agent AI Consortium (12 specialized personas)
- **Secondary**: Original game editor (now background tool)
- **Current Focus**: Deep Research Engine (Phase 6)
- **Ultimate Goal**: Complete cognitive amplification platform replacing multiple tools

**12 Expert Personas**:
1. üë®‚Äçüè´ Master Teacher - Educational expertise, Socratic method
2. üìñ Classical Educator - Classical trivium, great books, virtue
3. üìä Strategist - Strategic thinking, vision, planning
4. ‚õ™ Theologian - Theology, philosophy, ethics
5. üèóÔ∏è Technical Architect - Software architecture, systems design
6. ‚úçÔ∏è Writer - Creative writing, storytelling, editing
7. üî¨ Analyst - Data analysis, evidence, critical thinking
8. üêõ Debugger - Critical analysis, flaw identification
9. üé® UX Designer - User experience, design patterns
10. üì¢ Marketing Strategist - Marketing, positioning, growth
11. üéÆ Game Designer - Game mechanics, engagement, flow
12. üëæ Gen-Alpha Expert - Youth culture, digital natives

**Orchestration Modes**:
- Panel Discussion (all agents respond sequentially)
- Consensus Voting (agents debate and vote)
- Debate Mode (focused argumentation)
- Live Conversation (turn-taking discussion - most engaging!)
- Deep Research (multi-agent analysis of sources)

---

## üéØ Current Priority (Phase 6 Week 7-8)

**Status**: Week 5-6 (Multi-agent analysis) COMPLETE ‚úÖ  
**Next Up**: Week 7-8 (Research memory & export)

**What's Working Now** (Phase 6 Week 1-6):
- ‚úÖ Search across Tavily/Brave/Serper (Day 1)
- ‚úÖ Content extraction with Mozilla Readability (Day 2)
- ‚úÖ Semantic chunking for LLM processing (Day 2)
- ‚úÖ ResearchAnalyzer class with 12-persona orchestration (Day 3)
- ‚úÖ Intelligent chunk sampling to stay under 200K token limit (Day 3 bug fix)
- ‚úÖ Scrollable output UI that displays all content (Day 3 critical fix)
- ‚úÖ Executive synthesis + individual expert analyses
- ‚úÖ Beautiful collapsible markdown rendering
- ‚úÖ Respects selected personas (4 experts vs all 12)

**Recent Critical Fixes** (Dec 16 Evening):
1. **Token Overflow** (Dec 16 Afternoon):
   - Problem: 279 chunks = 217K tokens > 200K limit ‚Üí all 12 analyses failed
   - Solution: Intelligent sampling of 12 representative chunks
   - Strategy: Beginning (3) + Early Middle (3) + Late Middle (3) + End (3)
   - Result: Analyses complete successfully with context preserved

2. **Scrolling Issue** (Dec 16 Evening):
   - Problem: Research output displayed but couldn't scroll to see all content
   - Root Cause: `.research-results` had `overflow:hidden`, preventing scrolling
   - Solution: Changed to `overflow-y:auto` with unified scrolling
   - Removed: Nested scrollbars from child elements (single parent scrolls all)
   - Result: Smooth scrolling with beautiful blue scrollbar, all content accessible

**Architecture** (Scrolling Hierarchy):
```
.multi-agent-results (always scrollable)
  ‚îî‚îÄ .research-results (NOW scrollable - unified master scroller)
       ‚îú‚îÄ .research-header (fixed at top)
       ‚îú‚îÄ .analysis-section (expands naturally)
       ‚îÇ    ‚îú‚îÄ .analysis-synthesis (executive summary)
       ‚îÇ    ‚îî‚îÄ .analysis-list (12 expert perspectives)
       ‚îú‚îÄ .extracted-content-section (expands naturally)
       ‚îî‚îÄ .research-results-list (search results, expands naturally)
```

**What Happens Next** (Phase 6 Week 7-8):
1. ‚úÖ Test research query with fixed token sampling ‚Üí CONFIRMED WORKING
2. ‚úÖ Verify all 12 analyses succeed ‚Üí CONFIRMED WORKING
3. ‚úÖ Fix scrolling issue in research output ‚Üí FIXED
4. ‚è≥ Implement research memory (save/load research sessions)
5. ‚è≥ Add export capabilities (PDF, Markdown, JSON)
6. ‚è≥ Citation tracking and source management
7. üéØ Move to Phase 7 (YouTube/Video Intelligence)

---

## üíª Technical Stack

### Core Technologies
- **Frontend**: Vanilla JavaScript (ES6+), no frameworks
- **Backend**: Node.js + Netlify Serverless Functions
- **Orchestration**: LangGraph.js state machines
- **AI Provider**: Anthropic Claude (Sonnet 4.5, Opus 4.5, Haiku 4.5)
- **Also Supports**: OpenAI GPT (4, 4.1, 5, 5.2, 5-mini)

### Phase 6 Research Stack
- **Search**: Tavily AI, Brave Search API, Serper API
- **Content Extraction**: Mozilla Readability, Cheerio, jsdom
- **Text Processing**: Semantic chunking (~4000 token chunks, 200 token overlap)
- **Analysis**: 12-persona multi-agent orchestration

### Infrastructure
- **Hosting**: Netlify (serverless, auto-deploy from GitHub)
- **Version Control**: Git + GitHub
- **Development**: Custom Node.js dev server (port 8888)
- **Storage**: Currently localStorage (Phase 11 will add persistent database)

---

## üìä Project Status at a Glance

### Completed Capabilities
‚úÖ 12-persona multi-agent system  
‚úÖ 4 orchestration modes (Panel, Consensus, Debate, Conversation)  
‚úÖ Deep Research mode with multi-agent analysis  
‚úÖ Memory system (agent-memory.js)  
‚úÖ Multi-LLM support (Claude + GPT)  
‚úÖ Search foundation (Tavily/Brave/Serper)  
‚úÖ Content extraction & chunking (Mozilla Readability)  
‚úÖ ResearchAnalyzer with intelligent token sampling  
‚úÖ Scrollable research UI with collapsible sections  
‚úÖ Executive synthesis + 12 expert perspectives  
‚úÖ Markdown rendering in analysis output  
‚úÖ Comprehensive documentation (26,000+ words)

### In Progress
üîÑ Phase 6 Week 7-8: Research memory & export (next sprint)

### Next Up
‚è≥ Phase 6 Week 7-8: Research memory & export  
‚è≥ Phase 7: YouTube & video processing  
‚è≥ Phase 8: Creative content generation  
‚è≥ Phase 9: Development environment  
‚è≥ Phase 10-12: Integration, autonomy, scale

### Known Limitations
- No persistent storage yet (localStorage only)
- No user accounts/authentication
- Desktop-first (no mobile optimization yet)
- Single-user only (team features in Phase 11)

---

## üöÄ Development Velocity

**Time Investment So Far**: ~7-10 hours total (Phases 1-6 Day 3)  
**Development Speed**: 10-20x normal (AI-assisted rapid development)  
**Documentation**: Intentionally over-documented (10:1 docs-to-code ratio)  
**Philosophy**: Ship fast, iterate based on real usage

**Cost Per Session**: $0.10-0.30 (Claude Sonnet)  
**Monthly API Costs**: ~$15-20 (current usage)

---

## üìñ Context Loading Strategy for AI Conversations

### For Claude Sonnet 4.5 (200K Token Context Window)
Sonnet 4.5 has ~200K token capacity, equivalent to:
- ~150,000 words
- ~500 pages of text
- **Your entire project docs fit comfortably!**

### Tier 1: Always Load (5-10K tokens)
**Essential for every conversation:**
- This file (CONTEXT_LOADER.md) - Master index
- CURRENT_STATUS.md - Live development state
- Current phase objectives
- Last 3 interactions from session

### Tier 2: Load When Relevant (20-40K tokens)
**For feature development or planning:**
- FUTURE_CAPABILITIES_ROADMAP.md - Complete vision
- PHASE_6_IMPLEMENTATION_PLAN.md (or current phase plan)
- Technical architecture docs
- Persona definitions

### Tier 3: Reference on Demand (Remaining Capacity)
**Deep dives and historical context:**
- Biography and mission documents
- Historical phase completion summaries
- Legacy planning documents
- Full conversation history

---

## üé¨ Quick Start Templates for New Conversations

### Template 1: Continue Current Work
```
Continuing work on UCAS - Universal Cognitive Amplification System.

Context loaded:
- CONTEXT_LOADER.md (master index)
- CURRENT_STATUS.md (live state)
- Phase 6 Day 3 (Multi-agent research analysis)

Current status: Testing token limit fix in ResearchAnalyzer
Next: Validate 12-persona analysis works with intelligent chunk sampling

Proceed from documented state in CURRENT_STATUS.md
```

### Template 2: Strategic Planning Session
```
Strategic planning for UCAS future phases.

Context needed:
- CONTEXT_LOADER.md
- FUTURE_CAPABILITIES_ROADMAP.md (Phases 7-12)
- COGNITIVE_AMPLIFICATION_VISION.md
- Current completion: Phase 6 Day 3

Goal: [Describe planning objective]

Please review future plans before discussion.
```

### Template 3: Bug Fixing / Debugging
```
Debugging issue in Phase 6 research system.

Context:
- CONTEXT_LOADER.md (overview)
- CURRENT_STATUS.md (current state)
- PHASE_6_DAY_1_COMPLETE.md (search foundation)
- Recent changes: [Describe what changed]

Issue: [Describe problem]
Expected: [What should happen]
Actual: [What is happening]

System state: [Relevant files/functions]
```

### Template 4: Feature Implementation
```
Implementing [Feature Name] for UCAS.

Context:
- CONTEXT_LOADER.md
- FUTURE_CAPABILITIES_ROADMAP.md (Phase X section)
- CURRENT_STATUS.md
- Related files: [List relevant existing code]

Requirements:
- [Requirement 1]
- [Requirement 2]

Approach: [Proposed implementation strategy if known]
```

---

## üîß Context Management Recommendations

### Automatic Context Injection (Future Enhancement)
Build a system that automatically includes context in AI calls:

```javascript
class ProjectContext {
  constructor() {
    this.core = this.loadCoreContext();        // Mission, values, current phase
    this.session = this.loadSessionContext();  // Active work this session
    this.persona = this.loadPersonaContext();  // Agent-specific knowledge
  }
  
  buildPrompt(userMessage, tier = 2) {
    let context = `[CORE CONTEXT]\n${this.core}\n\n`;
    
    if (tier >= 2) {
      context += `[TECHNICAL CONTEXT]\n${this.getTechnicalContext()}\n\n`;
    }
    
    if (tier >= 3) {
      context += `[HISTORICAL CONTEXT]\n${this.getHistoricalContext()}\n\n`;
    }
    
    context += `[USER MESSAGE]\n${userMessage}`;
    
    return context;
  }
  
  loadCoreContext() {
    return {
      identity: readFile('01-BIOGRAPHY-STORY.md'),
      mission: readFile('MISSION-STATEMENT.md'),
      currentPhase: readFile('CURRENT_STATUS.md'),
      architecture: readFile('docs/TECHNICAL_ARCHITECTURE.md')
    };
  }
}
```

### Memory Expansion Needed (Phase 11)
Enhance agent-memory.js to include:
- Project milestones and completion dates
- Architectural decisions with rationale
- Key patterns and coding conventions
- Cross-session continuity
- Decision logs (why we chose X over Y)

### "Project Brain" Concept
A persistent knowledge base that:
- Indexes all documentation with semantic search
- Tracks decisions and their rationale
- Maintains architectural principles
- Stores key conversations and insights
- Enables "tell me what we decided about X"

---

## üìÇ File Organization for Context

### Living Documents (Update Frequently)
üìù **CURRENT_STATUS.md** - Updated daily/after each session  
üìù **PROJECT_STATUS.md** - Updated weekly  
üìù **CONTEXT_LOADER.md** - Updated when major changes occur (this file!)

### Strategic Documents (Update Per Phase)
üìã **FUTURE_CAPABILITIES_ROADMAP.md** - Update when plans change  
üìã **PHASE_X_IMPLEMENTATION_PLAN.md** - Update during active phase  
üìã **COGNITIVE_AMPLIFICATION_VISION.md** - Update when vision evolves

### Historical Documents (Archive, Don't Update)
üì¶ **PHASE_X_COMPLETE.md** - Completion summaries (locked after phase ends)  
üì¶ **MASTER-PLAN.md** - Original homeschool vision (historical reference)  
üì¶ **MASTER_ROADMAP.md** - Game editor roadmap (historical reference)

### Reference Documents (Rarely Change)
üìö **AGENT_COUNCIL_GUIDE.md** - Multi-agent architecture principles  
üìö **FELLOWSHIP_GUIDE.md** - Team collaboration principles  
üìö **personas/*.md** - Individual persona definitions

---

## üéì Best Practices for Context Continuity

### Starting Each Day
1. Review CURRENT_STATUS.md for overnight updates
2. Check this file (CONTEXT_LOADER.md) for any changes
3. Scan recent git commits for what changed
4. Load relevant phase documentation

### When Switching Tasks
1. Update CURRENT_STATUS.md with completed work
2. Note any blockers or open questions
3. Commit changes to git
4. Start new task with fresh context load

### When Onboarding New AI Assistant
1. **Start with**: CONTEXT_LOADER.md (this file)
2. **Then read**: CURRENT_STATUS.md
3. **Then review**: Current phase plan (PHASE_X_IMPLEMENTATION_PLAN.md)
4. **Optional**: Completed phase summaries for background

### When Context Gets Stale
**Signs you need to reload context:**
- AI suggests features already implemented
- AI asks questions answered in docs
- AI doesn't remember recent decisions
- AI proposes approaches we already rejected

**Solution:**
- Copy key excerpts from CURRENT_STATUS.md into conversation
- Reference specific completed phases
- Point to architectural decisions in documentation

---

## üîÆ Future Enhancements (Phase 11)

### Persistent Context System
When we implement Phase 11 (Persistent Memory), we'll add:

1. **Context Auto-Loader**: Automatically inject project context into every AI call
2. **Smart Context Selection**: Only include relevant context based on task type
3. **Context Compression**: Summarize old context to fit more in window
4. **Context Versioning**: Track how project context evolves over time
5. **Context Search**: "Show me all decisions about authentication"
6. **Context Graph**: Visual map of how concepts connect

### Agent Memory Enhancement
Expand agent-memory.js to include:
- Cross-session memory (remember conversations from days/weeks ago)
- Project-level facts (stored once, accessed by all agents)
- Decision logs (why we chose X, rejected Y, with full context)
- Architecture principles (automatically enforced)
- Pattern library (recognized coding patterns)

---

## üí° Tips for Effective Context Usage

### DO:
‚úÖ Start every important conversation by referencing this file  
‚úÖ Keep CURRENT_STATUS.md ruthlessly up-to-date  
‚úÖ Use specific document references when asking questions  
‚úÖ Link to line numbers for precision: `file.js#L123-L456`  
‚úÖ Include relevant error messages and console output  
‚úÖ Mention recent changes that might affect current work

### DON'T:
‚ùå Assume AI remembers previous unrelated conversations  
‚ùå Reference obsolete documents (check last updated date)  
‚ùå Skip context loading for "quick questions" (they compound)  
‚ùå Let documentation drift from reality  
‚ùå Forget to document major decisions

---

## üìû Emergency Context Recovery

**If an AI conversation goes off the rails:**

1. **Stop and reset**: "Let's pause and reload context"
2. **Provide core files**: Share CONTEXT_LOADER.md + CURRENT_STATUS.md
3. **State current objective**: "We're working on X, currently at Y state"
4. **Clarify misconceptions**: "That feature is already done" or "We decided against that approach"
5. **Link to evidence**: Point to specific files/lines showing current state
6. **Resume with clarity**: "Now, continuing from [clear starting point]..."

---

## üéØ Success Metrics for Context Management

**Good context management means:**
- AI rarely asks about things documented
- AI suggests appropriate next steps
- AI remembers recent decisions
- AI builds on existing work rather than starting over
- Conversations feel continuous, not disjointed

**Poor context management means:**
- AI suggests rebuilding working features
- AI asks same questions repeatedly
- AI proposes rejected approaches
- AI unaware of recent progress
- Conversations feel like Groundhog Day

---

**Remember**: Context is everything. The 5 minutes spent loading proper context saves hours of confused back-and-forth.

**This file is your North Star for project continuity. Reference it often.**

---

*Last Updated: December 16, 2025*  
*Next Review: After Phase 6 completion*

---

**Remember**: Sonnet 4.5's 200K context is HUGE. We can comfortably load:
- All mission/strategy docs (~10K tokens)
- All technical specs (~20K tokens)  
- All persona definitions (~5K tokens)
- All phase documentation (~30K tokens)
- Current conversation (~30K tokens)
- **Still have 100K+ tokens remaining!**

Don't be shy about loading context. The model can handle it!
